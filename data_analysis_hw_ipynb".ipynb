{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olyadiya/MA-intro-to-python/blob/main/data_analysis_hw_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa2G_JERA7yn"
      },
      "source": [
        "## Задание 1: выгрузка файлов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrtdr5UF_TyT"
      },
      "source": [
        "1. Зайдите в репозиторий датасетов для обучения диалоговых систем\n",
        "2. Найдите все файлы с расширением *.txt (их всего 5 в репозитории)\n",
        "3. Выгрузите каждый файл с помощью утилиты `wget`\n",
        "- Для этого откройте датасет в браузере, например, https://github.com/Phylliida/Dialogue-Datasets/blob/master/TwitterLowerAsciiCorpus.txt\n",
        "- Затем найдите кнопку `raw`, которая откроет вам файл \"как есть\" (как в блокноте!)\n",
        "- Скопируйте ссылку на файл (она выглядит так: https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterLowerAsciiCorpus.txt)\n",
        "- Воспользуйтесь `wget`\n",
        "---\n",
        "Как использовать `wget`:\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swBssiVj90wr",
        "outputId": "a5bd537e-87ec-4ebf-a755-a354672cdf37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-12-19 06:45:59--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterLowerAsciiCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 593707 (580K) [text/plain]\n",
            "Saving to: ‘twitter.txt’\n",
            "\n",
            "twitter.txt         100%[===================>] 579.79K  --.-KB/s    in 0.09s   \n",
            "\n",
            "2025-12-19 06:46:00 (6.20 MB/s) - ‘twitter.txt’ saved [593707/593707]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterLowerAsciiCorpus.txt -O twitter.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kekDrEGyAXUO"
      },
      "source": [
        "Здесь:\n",
        "- ! указывает на то, что это консольная утилита, а не код на python\n",
        "- после wget идет полный адрес ссылки для скачивания файла\n",
        "- после параметра `-O` указываем название файла, под которым мы хотим скачать файл"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FAveoWrAWm-",
        "outputId": "97f7c0f0-15e5-4112-e80a-0ada82612d7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-19 08:26:00--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterLowerAsciiCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 593707 (580K) [text/plain]\n",
            "Saving to: ‘lower_corpus.txt’\n",
            "\n",
            "lower_corpus.txt    100%[===================>] 579.79K  --.-KB/s    in 0.09s   \n",
            "\n",
            "2025-12-19 08:26:01 (6.24 MB/s) - ‘lower_corpus.txt’ saved [593707/593707]\n",
            "\n",
            "--2025-12-19 08:26:01--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterConvCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 612338 (598K) [text/plain]\n",
            "Saving to: ‘convo_corpus.txt’\n",
            "\n",
            "convo_corpus.txt    100%[===================>] 597.99K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-12-19 08:26:01 (5.78 MB/s) - ‘convo_corpus.txt’ saved [612338/612338]\n",
            "\n",
            "--2025-12-19 08:26:01--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/MovieCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16976724 (16M) [text/plain]\n",
            "Saving to: ‘movie_corpus.txt’\n",
            "\n",
            "movie_corpus.txt    100%[===================>]  16.19M  67.2MB/s    in 0.2s    \n",
            "\n",
            "2025-12-19 08:26:01 (67.2 MB/s) - ‘movie_corpus.txt’ saved [16976724/16976724]\n",
            "\n",
            "--2025-12-19 08:26:02--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/BNCSplitWordsCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19173003 (18M) [text/plain]\n",
            "Saving to: ‘splited_corpus.txt’\n",
            "\n",
            "splited_corpus.txt  100%[===================>]  18.28M  69.2MB/s    in 0.3s    \n",
            "\n",
            "2025-12-19 08:26:02 (69.2 MB/s) - ‘splited_corpus.txt’ saved [19173003/19173003]\n",
            "\n",
            "--2025-12-19 08:26:02--  https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/BNCCorpus.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19081694 (18M) [text/plain]\n",
            "Saving to: ‘bnc_corpus.txt’\n",
            "\n",
            "bnc_corpus.txt      100%[===================>]  18.20M  69.1MB/s    in 0.3s    \n",
            "\n",
            "2025-12-19 08:26:03 (69.1 MB/s) - ‘bnc_corpus.txt’ saved [19081694/19081694]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Ваш код здесь: повторите процедуру для остальных файлов (всего должно быть 5 файлов)\n",
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterLowerAsciiCorpus.txt -O lower_corpus.txt\n",
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/TwitterConvCorpus.txt -O convo_corpus.txt\n",
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/MovieCorpus.txt -O movie_corpus.txt\n",
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/BNCSplitWordsCorpus.txt -O splited_corpus.txt\n",
        "!wget https://raw.githubusercontent.com/Phylliida/Dialogue-Datasets/refs/heads/master/BNCCorpus.txt -O bnc_corpus.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLaq0LFXBBI9"
      },
      "source": [
        "## Задание 2: открываем файлы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjNtW5R1BI7d"
      },
      "source": [
        "Изучите туториал по работе с файлами, который вы получили в чате. Каждый файл нужно теперь открыть, а его содержание - записать в переменную *любым удобным вам способом*\n",
        "\n",
        "Пример:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "_uJqiGUpBFEV",
        "outputId": "65ad4296-3edb-4da4-ae48-0c8053b4a592"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл успешно загружен!\n",
            "Размер файла: 593707 символов\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"what's up dadyo when did you get back on twitter? haha\\nlike 2 weeks ago and it's going as terribly a\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "# Открываем файл с указанием кодировки\n",
        "file = open('twitter.txt', 'r', encoding='utf-8')\n",
        "dataset_content = file.read()\n",
        "file.close()\n",
        "\n",
        "print(\"Файл успешно загружен!\")\n",
        "print(f\"Размер файла: {len(dataset_content)} символов\")\n",
        "dataset_content[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "yrYxdTj6BGv_",
        "outputId": "b2903119-fc71-4d51-bfe7-e4600b8cee7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл успешно загружен!\n",
            "Размер файла: 593707 символов\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"what's up dadyo when did you get back on twitter? haha\\nlike 2 weeks ago and it's going as terribly a\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "file = open('lower_corpus.txt', 'r', encoding='utf-8')\n",
        "lower_corpus = file.read()\n",
        "file.close()\n",
        "\n",
        "print(\"Файл успешно загружен!\")\n",
        "print(f\"Размер файла: {len(dataset_content)} символов\")\n",
        "dataset_content[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "pa90PPdWfgGF",
        "outputId": "1384b2df-032e-4fe2-c9e6-7250c28d3db5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл успешно загружен!\n",
            "Размер файла: 593707 символов\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"what's up dadyo when did you get back on twitter? haha\\nlike 2 weeks ago and it's going as terribly a\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "file = open('convo_corpus.txt', 'r', encoding='utf-8')\n",
        "convo_corpus = file.read()\n",
        "file.close()\n",
        "\n",
        "print(\"Файл успешно загружен!\")\n",
        "print(f\"Размер файла: {len(dataset_content)} символов\")\n",
        "dataset_content[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "opKOElVgfivz",
        "outputId": "9fef83eb-8966-417d-a4d1-f7b5cd4d55d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл успешно загружен!\n",
            "Размер файла: 593707 символов\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"what's up dadyo when did you get back on twitter? haha\\nlike 2 weeks ago and it's going as terribly a\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "file = open('movie_corpus.txt', 'r', encoding='utf-8')\n",
        "movie_corpus = file.read()\n",
        "file.close()\n",
        "\n",
        "print(\"Файл успешно загружен!\")\n",
        "print(f\"Размер файла: {len(dataset_content)} символов\")\n",
        "dataset_content[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "7tkWqdkIflSC",
        "outputId": "7f000593-c4ae-4f2b-8f1f-ab81d37b1322"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл успешно загружен!\n",
            "Размер файла: 593707 символов\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"what's up dadyo when did you get back on twitter? haha\\nlike 2 weeks ago and it's going as terribly a\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "file = open('splited_corpus.txt', 'r', encoding='utf-8')\n",
        "splited_corpus = file.read()\n",
        "file.close()\n",
        "\n",
        "print(\"Файл успешно загружен!\")\n",
        "print(f\"Размер файла: {len(dataset_content)} символов\")\n",
        "dataset_content[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "Dv05NBPKfqhK",
        "outputId": "8df1633a-2c7d-4b51-f2d7-190ba18b8dc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл успешно загружен!\n",
            "Размер файла: 593707 символов\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"what's up dadyo when did you get back on twitter? haha\\nlike 2 weeks ago and it's going as terribly a\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "file = open('bnc_corpus.txt', 'r', encoding='utf-8')\n",
        "bnc_corpus = file.read()\n",
        "file.close()\n",
        "\n",
        "print(\"Файл успешно загружен!\")\n",
        "print(f\"Размер файла: {len(dataset_content)} символов\")\n",
        "dataset_content[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSc5RUhgBu_3"
      },
      "source": [
        "## Задание 3: первичный анализ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui-vA_4wB76-"
      },
      "source": [
        "Выведем статистику для каждого файла по образцу:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XliSd4K4Byym",
        "outputId": "892eed8f-3d5b-4af2-9409-5de0cc05d830"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всего строк: 16557\n",
            "Непустых строк: 10514\n",
            "Всего слов: 112977\n",
            "Всего символов: 577151\n",
            "Макс. длина строки: 146\n",
            "Мин. длина строки: 0\n"
          ]
        }
      ],
      "source": [
        "# 1. Разбиваем содержание файла на строки\n",
        "lines = lower_corpus.split('\\n')\n",
        "\n",
        "# 2. Считаем статистику (используйте цикл for и вот такие счетчики >)\n",
        "total_lines = len(lines)         # общее количество строк\n",
        "total_words = 0         # общее количество слов\n",
        "total_chars = 0         # общее количество символов\n",
        "non_empty_lines = 0     # количество непустых строк (длина такой строки больше 0)\n",
        "max_line_length = 0   # минимальная длина строки\n",
        "min_line_length = 0   # максимальная длина строки\n",
        "\n",
        "# Ваш код здесь: реализуйте логику для получения таких статистик\n",
        "\n",
        "for line in lines:\n",
        "\n",
        "    line_length = len(line)\n",
        "    total_chars += line_length\n",
        "\n",
        "\n",
        "    words = line.split()\n",
        "    total_words += len(words)\n",
        "\n",
        "\n",
        "    if line_length > 0:\n",
        "        non_empty_lines += 1\n",
        "\n",
        "\n",
        "    if line_length > max_line_length:\n",
        "        max_line_length = line_length\n",
        "\n",
        "\n",
        "    if line_length > 0 and line_length < min_line_length:\n",
        "        min_line_length = line_length\n",
        "\n",
        "# Выводим результат на экран для каждого файла в таком формате:\n",
        "print(f\"Всего строк: {total_lines}\")\n",
        "print(f\"Непустых строк: {non_empty_lines}\")\n",
        "print(f\"Всего слов: {total_words}\")\n",
        "print(f\"Всего символов: {total_chars}\")\n",
        "print(f\"Макс. длина строки: {max_line_length}\")\n",
        "print(f\"Мин. длина строки: {min_line_length}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68VQh81xhmE1",
        "outputId": "87e5062e-5e2a-4f18-81d8-988a0b50a744"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всего строк: 16557\n",
            "Непустых строк: 10628\n",
            "Всего слов: 114910\n",
            "Всего символов: 582000\n",
            "Макс. длина строки: 146\n",
            "Мин. длина строки: 0\n"
          ]
        }
      ],
      "source": [
        "# 1. Разбиваем содержание файла на строки\n",
        "lines = convo_corpus.split('\\n')\n",
        "\n",
        "# 2. Считаем статистику (используйте цикл for и вот такие счетчики >)\n",
        "total_lines = len(lines)         # общее количество строк\n",
        "total_words = 0         # общее количество слов\n",
        "total_chars = 0         # общее количество символов\n",
        "non_empty_lines = 0     # количество непустых строк (длина такой строки больше 0)\n",
        "max_line_length = 0   # минимальная длина строки\n",
        "min_line_length = 0   # максимальная длина строки\n",
        "\n",
        "# Ваш код здесь: реализуйте логику для получения таких статистик\n",
        "\n",
        "for line in lines:\n",
        "\n",
        "    line_length = len(line)\n",
        "    total_chars += line_length\n",
        "\n",
        "\n",
        "    words = line.split()\n",
        "    total_words += len(words)\n",
        "\n",
        "\n",
        "    if line_length > 0:\n",
        "        non_empty_lines += 1\n",
        "\n",
        "\n",
        "    if line_length > max_line_length:\n",
        "        max_line_length = line_length\n",
        "\n",
        "\n",
        "    if line_length > 0 and line_length < min_line_length:\n",
        "        min_line_length = line_length\n",
        "\n",
        "# Выводим результат на экран для каждого файла в таком формате:\n",
        "print(f\"Всего строк: {total_lines}\")\n",
        "print(f\"Непустых строк: {non_empty_lines}\")\n",
        "print(f\"Всего слов: {total_words}\")\n",
        "print(f\"Всего символов: {total_chars}\")\n",
        "print(f\"Макс. длина строки: {max_line_length}\")\n",
        "print(f\"Мин. длина строки: {min_line_length}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydmuUYI7hMwS",
        "outputId": "a4db2fbc-3b51-40a9-e80a-a109cc343a18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всего строк: 304714\n",
            "Непустых строк: 304713\n",
            "Всего слов: 3185395\n",
            "Всего символов: 16672011\n",
            "Макс. длина строки: 3039\n",
            "Мин. длина строки: 0\n"
          ]
        }
      ],
      "source": [
        "# 1. Разбиваем содержание файла на строки\n",
        "lines = movie_corpus.split('\\n')\n",
        "\n",
        "# 2. Считаем статистику (используйте цикл for и вот такие счетчики >)\n",
        "total_lines = len(lines)         # общее количество строк\n",
        "total_words = 0         # общее количество слов\n",
        "total_chars = 0         # общее количество символов\n",
        "non_empty_lines = 0     # количество непустых строк (длина такой строки больше 0)\n",
        "max_line_length = 0   # минимальная длина строки\n",
        "min_line_length = 0   # максимальная длина строки\n",
        "\n",
        "# Ваш код здесь: реализуйте логику для получения таких статистик\n",
        "\n",
        "for line in lines:\n",
        "\n",
        "    line_length = len(line)\n",
        "    total_chars += line_length\n",
        "\n",
        "\n",
        "    words = line.split()\n",
        "    total_words += len(words)\n",
        "\n",
        "\n",
        "    if line_length > 0:\n",
        "        non_empty_lines += 1\n",
        "\n",
        "\n",
        "    if line_length > max_line_length:\n",
        "        max_line_length = line_length\n",
        "\n",
        "\n",
        "    if line_length > 0 and line_length < min_line_length:\n",
        "        min_line_length = line_length\n",
        "\n",
        "# Выводим результат на экран для каждого файла в таком формате:\n",
        "print(f\"Всего строк: {total_lines}\")\n",
        "print(f\"Непустых строк: {non_empty_lines}\")\n",
        "print(f\"Всего слов: {total_words}\")\n",
        "print(f\"Всего символов: {total_chars}\")\n",
        "print(f\"Макс. длина строки: {max_line_length}\")\n",
        "print(f\"Мин. длина строки: {min_line_length}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7_BSUYZhrte",
        "outputId": "e7887355-f882-468b-ddca-426e42d7c82b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всего строк: 611015\n",
            "Непустых строк: 606486\n",
            "Всего слов: 4052241\n",
            "Всего символов: 18561989\n",
            "Макс. длина строки: 2773\n",
            "Мин. длина строки: 0\n"
          ]
        }
      ],
      "source": [
        "# 1. Разбиваем содержание файла на строки\n",
        "lines = splited_corpus.split('\\n')\n",
        "\n",
        "# 2. Считаем статистику (используйте цикл for и вот такие счетчики >)\n",
        "total_lines = len(lines)         # общее количество строк\n",
        "total_words = 0         # общее количество слов\n",
        "total_chars = 0         # общее количество символов\n",
        "non_empty_lines = 0     # количество непустых строк (длина такой строки больше 0)\n",
        "max_line_length = 0   # минимальная длина строки\n",
        "min_line_length = 0   # максимальная длина строки\n",
        "\n",
        "# Ваш код здесь: реализуйте логику для получения таких статистик\n",
        "\n",
        "for line in lines:\n",
        "\n",
        "    line_length = len(line)\n",
        "    total_chars += line_length\n",
        "\n",
        "\n",
        "    words = line.split()\n",
        "    total_words += len(words)\n",
        "\n",
        "\n",
        "    if line_length > 0:\n",
        "        non_empty_lines += 1\n",
        "\n",
        "\n",
        "    if line_length > max_line_length:\n",
        "        max_line_length = line_length\n",
        "\n",
        "\n",
        "    if line_length > 0 and line_length < min_line_length:\n",
        "        min_line_length = line_length\n",
        "\n",
        "# Выводим результат на экран для каждого файла в таком формате:\n",
        "print(f\"Всего строк: {total_lines}\")\n",
        "print(f\"Непустых строк: {non_empty_lines}\")\n",
        "print(f\"Всего слов: {total_words}\")\n",
        "print(f\"Всего символов: {total_chars}\")\n",
        "print(f\"Макс. длина строки: {max_line_length}\")\n",
        "print(f\"Мин. длина строки: {min_line_length}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WP6JSzgPhsfS",
        "outputId": "cb2ffcbd-6b70-4566-c605-8fb3f562c277"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всего строк: 611015\n",
            "Непустых строк: 606486\n",
            "Всего слов: 3719853\n",
            "Всего символов: 18470680\n",
            "Макс. длина строки: 2702\n",
            "Мин. длина строки: 0\n"
          ]
        }
      ],
      "source": [
        "# 1. Разбиваем содержание файла на строки\n",
        "lines = bnc_corpus.split('\\n')\n",
        "\n",
        "# 2. Считаем статистику (используйте цикл for и вот такие счетчики >)\n",
        "total_lines = len(lines)         # общее количество строк\n",
        "total_words = 0         # общее количество слов\n",
        "total_chars = 0         # общее количество символов\n",
        "non_empty_lines = 0     # количество непустых строк (длина такой строки больше 0)\n",
        "max_line_length = 0   # минимальная длина строки\n",
        "min_line_length = 0   # максимальная длина строки\n",
        "\n",
        "# Ваш код здесь: реализуйте логику для получения таких статистик\n",
        "\n",
        "for line in lines:\n",
        "\n",
        "    line_length = len(line)\n",
        "    total_chars += line_length\n",
        "\n",
        "\n",
        "    words = line.split()\n",
        "    total_words += len(words)\n",
        "\n",
        "\n",
        "    if line_length > 0:\n",
        "        non_empty_lines += 1\n",
        "\n",
        "\n",
        "    if line_length > max_line_length:\n",
        "        max_line_length = line_length\n",
        "\n",
        "\n",
        "    if line_length > 0 and line_length < min_line_length:\n",
        "        min_line_length = line_length\n",
        "\n",
        "# Выводим результат на экран для каждого файла в таком формате:\n",
        "print(f\"Всего строк: {total_lines}\")\n",
        "print(f\"Непустых строк: {non_empty_lines}\")\n",
        "print(f\"Всего слов: {total_words}\")\n",
        "print(f\"Всего символов: {total_chars}\")\n",
        "print(f\"Макс. длина строки: {max_line_length}\")\n",
        "print(f\"Мин. длина строки: {min_line_length}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aptZI3yhEOlW"
      },
      "source": [
        "## Задание 4: чистка текста"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHDEshS1DMo4",
        "outputId": "f6814dbd-f4a8-4f92-c561-d9a9e74c51f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример очищенной строки: whats up dadyo when did you get back on twitter haha...\n",
            "Всего очищенных слов: 104907\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "cleaned_lines = [] # чистим текст построчно (сохраняем каждую очищенную строку в список)\n",
        "all_cleaned_words = [] # также сохраняем все слова после очистки в список\n",
        "\n",
        "with open('lower_corpus.txt', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "for line in lines:\n",
        "    line = line.strip()\n",
        "\n",
        "    if not line:\n",
        "     continue\n",
        "\n",
        "    line = re.sub(r'[^a-zA-Zа-яА-Я0-9\\s]', '', line)\n",
        "    line = re.sub(r'\\s+', ' ', line)\n",
        "    line = line.lower()\n",
        "\n",
        "    cleaned_lines.append(line)\n",
        "\n",
        "    words = line.split()\n",
        "    for word in words:\n",
        "        if len(word) > 1:\n",
        "            all_cleaned_words.append(word)\n",
        "\n",
        "print(f\"Пример очищенной строки: {cleaned_lines[0][:100]}...\")\n",
        "print(f\"Всего очищенных слов: {len(all_cleaned_words)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ti-YGwC9kaQ5",
        "outputId": "b9a78650-2f56-4b94-9bf5-e241eaa18e78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример очищенной строки: whats up dadyo when did you get back on twitter haha...\n",
            "Всего очищенных слов: 104910\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "cleaned_lines = [] # чистим текст построчно (сохраняем каждую очищенную строку в список)\n",
        "all_cleaned_words = [] # также сохраняем все слова после очистки в список\n",
        "\n",
        "with open('convo_corpus.txt', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "for line in lines:\n",
        "    line = line.strip()\n",
        "\n",
        "    if not line:\n",
        "     continue\n",
        "\n",
        "    line = re.sub(r'[^a-zA-Zа-яА-Я0-9\\s]', '', line)\n",
        "    line = re.sub(r'\\s+', ' ', line)\n",
        "    line = line.lower()\n",
        "\n",
        "    cleaned_lines.append(line)\n",
        "\n",
        "    words = line.split()\n",
        "    for word in words:\n",
        "        if len(word) > 1:\n",
        "            all_cleaned_words.append(word)\n",
        "\n",
        "print(f\"Пример очищенной строки: {cleaned_lines[0][:100]}...\")\n",
        "print(f\"Всего очищенных слов: {len(all_cleaned_words)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GbExEqgkcpy",
        "outputId": "b7934454-74ce-40b3-cea5-112fe796ed34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример очищенной строки: colonel durnford william vereker i hear you ve been seeking officers...\n",
            "Всего очищенных слов: 3001928\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "cleaned_lines = [] # чистим текст построчно (сохраняем каждую очищенную строку в список)\n",
        "all_cleaned_words = [] # также сохраняем все слова после очистки в список\n",
        "\n",
        "with open('movie_corpus.txt', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "for line in lines:\n",
        "    line = line.strip()\n",
        "\n",
        "    if not line:\n",
        "     continue\n",
        "\n",
        "    line = re.sub(r'[^a-zA-Zа-яА-Я0-9\\s]', '', line)\n",
        "    line = re.sub(r'\\s+', ' ', line)\n",
        "    line = line.lower()\n",
        "\n",
        "    cleaned_lines.append(line)\n",
        "\n",
        "    words = line.split()\n",
        "    for word in words:\n",
        "        if len(word) > 1:\n",
        "            all_cleaned_words.append(word)\n",
        "\n",
        "print(f\"Пример очищенной строки: {cleaned_lines[0][:100]}...\")\n",
        "print(f\"Всего очищенных слов: {len(all_cleaned_words)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dav6KY5kdY8",
        "outputId": "27aa5cf9-22ac-464a-b6fd-3a9276b3cf56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример очищенной строки: you enjoyed yourself in america...\n",
            "Всего очищенных слов: 3754297\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "cleaned_lines = [] # чистим текст построчно (сохраняем каждую очищенную строку в список)\n",
        "all_cleaned_words = [] # также сохраняем все слова после очистки в список\n",
        "\n",
        "with open('splited_corpus.txt', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "for line in lines:\n",
        "    line = line.strip()\n",
        "\n",
        "    if not line:\n",
        "     continue\n",
        "\n",
        "    line = re.sub(r'[^a-zA-Zа-яА-Я0-9\\s]', '', line)\n",
        "    line = re.sub(r'\\s+', ' ', line)\n",
        "    line = line.lower()\n",
        "\n",
        "    cleaned_lines.append(line)\n",
        "\n",
        "    words = line.split()\n",
        "    for word in words:\n",
        "        if len(word) > 1:\n",
        "            all_cleaned_words.append(word)\n",
        "\n",
        "print(f\"Пример очищенной строки: {cleaned_lines[0][:100]}...\")\n",
        "print(f\"Всего очищенных слов: {len(all_cleaned_words)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S423g5lykd2o",
        "outputId": "7f569f53-5de3-4da9-b60e-d5f6c1d30810"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример очищенной строки: you enjoyed yourself in america...\n",
            "Всего очищенных слов: 3524835\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "cleaned_lines = [] # чистим текст построчно (сохраняем каждую очищенную строку в список)\n",
        "all_cleaned_words = [] # также сохраняем все слова после очистки в список\n",
        "\n",
        "with open('bnc_corpus.txt', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "for line in lines:\n",
        "    line = line.strip()\n",
        "\n",
        "    if not line:\n",
        "     continue\n",
        "\n",
        "    line = re.sub(r'[^a-zA-Zа-яА-Я0-9\\s]', '', line)\n",
        "    line = re.sub(r'\\s+', ' ', line)\n",
        "    line = line.lower()\n",
        "\n",
        "    cleaned_lines.append(line)\n",
        "\n",
        "    words = line.split()\n",
        "    for word in words:\n",
        "        if len(word) > 1:\n",
        "            all_cleaned_words.append(word)\n",
        "\n",
        "print(f\"Пример очищенной строки: {cleaned_lines[0][:100]}...\")\n",
        "print(f\"Всего очищенных слов: {len(all_cleaned_words)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvPQoLBzGvAS"
      },
      "source": [
        "## Задание 5: статистика"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iirxb-yneJqB"
      },
      "source": [
        "Часть 1: получаем статистику распределений длин слов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1Z1tTq5DQFA",
        "outputId": "aa343d62-d649-47df-ddcc-bf3d516c772a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слов после очистки: 3524835\n",
            "Символов после очистки: 14643162\n",
            "Распределение длин слов:\n",
            "  2 букв: 666389 слов\n",
            "  3 букв: 880968 слов\n",
            "  4 букв: 880766 слов\n",
            "  5 букв: 425302 слов\n",
            "  6 букв: 255069 слов\n",
            "  7 букв: 175610 слов\n",
            "  8 букв: 102856 слов\n",
            "  9 букв: 60865 слов\n",
            "  10 букв: 34706 слов\n",
            "  11 букв: 16675 слов\n",
            "  12 букв: 10611 слов\n",
            "  13 букв: 5627 слов\n",
            "  14 букв: 3330 слов\n",
            "  15 букв: 1970 слов\n",
            "  16 букв: 1292 слов\n",
            "  17 букв: 668 слов\n",
            "  18 букв: 558 слов\n",
            "  19 букв: 331 слов\n",
            "  20 букв: 262 слов\n",
            "  21 букв: 173 слов\n",
            "  22 букв: 162 слов\n",
            "  23 букв: 94 слов\n",
            "  24 букв: 98 слов\n",
            "  25 букв: 62 слов\n",
            "  26 букв: 45 слов\n",
            "  27 букв: 56 слов\n",
            "  28 букв: 32 слов\n",
            "  29 букв: 28 слов\n",
            "  30 букв: 31 слов\n",
            "  31 букв: 12 слов\n",
            "  32 букв: 34 слов\n",
            "  33 букв: 16 слов\n",
            "  34 букв: 14 слов\n",
            "  35 букв: 18 слов\n",
            "  36 букв: 17 слов\n",
            "  37 букв: 2 слов\n",
            "  38 букв: 3 слов\n",
            "  39 букв: 18 слов\n",
            "  40 букв: 3 слов\n",
            "  41 букв: 2 слов\n",
            "  42 букв: 6 слов\n",
            "  43 букв: 2 слов\n",
            "  44 букв: 3 слов\n",
            "  45 букв: 7 слов\n",
            "  47 букв: 4 слов\n",
            "  48 букв: 4 слов\n",
            "  49 букв: 1 слов\n",
            "  51 букв: 2 слов\n",
            "  53 букв: 1 слов\n",
            "  54 букв: 1 слов\n",
            "  56 букв: 2 слов\n",
            "  57 букв: 1 слов\n",
            "  58 букв: 1 слов\n",
            "  59 букв: 5 слов\n",
            "  60 букв: 7 слов\n",
            "  63 букв: 1 слов\n",
            "  65 букв: 4 слов\n",
            "  66 букв: 1 слов\n",
            "  87 букв: 1 слов\n",
            "  90 букв: 1 слов\n",
            "  104 букв: 1 слов\n",
            "  105 букв: 2 слов\n",
            "  112 букв: 1 слов\n",
            "  114 букв: 1 слов\n"
          ]
        }
      ],
      "source": [
        "with open('lower_corpus.txt', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "# Статистика по очищенным данным\n",
        "total_words = len(all_cleaned_words)\n",
        "total_chars = 0\n",
        "word_lengths = []\n",
        "\n",
        "# Ваш код здесь: создайте список длин слов word_lengths\n",
        "#                и посчитайте общее количество символов total_chars\n",
        "\n",
        "for word in all_cleaned_words:\n",
        "    word_len = len(word)\n",
        "    word_lengths.append(word_len)\n",
        "    total_chars += word_len\n",
        "\n",
        "# Анализ длин слов: допишите код для подсчета количества слов разной длины\n",
        "word_length_count = {}\n",
        "# Ваш код здесь: для каждого значения длины в списке word_lengths\n",
        "for length in word_lengths:\n",
        "    # если длина уже зафиксирована в word_length_count, то выполняем:\n",
        "    if length in word_length_count:\n",
        "        word_length_count[length] += 1\n",
        "    # иначе: выполняем:\n",
        "    else:\n",
        "        word_length_count[length] = 1\n",
        "\n",
        "# Ожидаемый результат:\n",
        "print(f\"Слов после очистки: {total_words}\")\n",
        "print(f\"Символов после очистки: {total_chars}\")\n",
        "print(\"Распределение длин слов:\")\n",
        "for length in sorted(word_length_count.keys()):\n",
        "    print(f\"  {length} букв: {word_length_count[length]} слов\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3fFDtwMlvI3",
        "outputId": "2ee0a9d0-1a4d-4edd-d974-1d0a14131e7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слов после очистки: 3524835\n",
            "Символов после очистки: 14643162\n",
            "Распределение длин слов:\n",
            "  2 букв: 666389 слов\n",
            "  3 букв: 880968 слов\n",
            "  4 букв: 880766 слов\n",
            "  5 букв: 425302 слов\n",
            "  6 букв: 255069 слов\n",
            "  7 букв: 175610 слов\n",
            "  8 букв: 102856 слов\n",
            "  9 букв: 60865 слов\n",
            "  10 букв: 34706 слов\n",
            "  11 букв: 16675 слов\n",
            "  12 букв: 10611 слов\n",
            "  13 букв: 5627 слов\n",
            "  14 букв: 3330 слов\n",
            "  15 букв: 1970 слов\n",
            "  16 букв: 1292 слов\n",
            "  17 букв: 668 слов\n",
            "  18 букв: 558 слов\n",
            "  19 букв: 331 слов\n",
            "  20 букв: 262 слов\n",
            "  21 букв: 173 слов\n",
            "  22 букв: 162 слов\n",
            "  23 букв: 94 слов\n",
            "  24 букв: 98 слов\n",
            "  25 букв: 62 слов\n",
            "  26 букв: 45 слов\n",
            "  27 букв: 56 слов\n",
            "  28 букв: 32 слов\n",
            "  29 букв: 28 слов\n",
            "  30 букв: 31 слов\n",
            "  31 букв: 12 слов\n",
            "  32 букв: 34 слов\n",
            "  33 букв: 16 слов\n",
            "  34 букв: 14 слов\n",
            "  35 букв: 18 слов\n",
            "  36 букв: 17 слов\n",
            "  37 букв: 2 слов\n",
            "  38 букв: 3 слов\n",
            "  39 букв: 18 слов\n",
            "  40 букв: 3 слов\n",
            "  41 букв: 2 слов\n",
            "  42 букв: 6 слов\n",
            "  43 букв: 2 слов\n",
            "  44 букв: 3 слов\n",
            "  45 букв: 7 слов\n",
            "  47 букв: 4 слов\n",
            "  48 букв: 4 слов\n",
            "  49 букв: 1 слов\n",
            "  51 букв: 2 слов\n",
            "  53 букв: 1 слов\n",
            "  54 букв: 1 слов\n",
            "  56 букв: 2 слов\n",
            "  57 букв: 1 слов\n",
            "  58 букв: 1 слов\n",
            "  59 букв: 5 слов\n",
            "  60 букв: 7 слов\n",
            "  63 букв: 1 слов\n",
            "  65 букв: 4 слов\n",
            "  66 букв: 1 слов\n",
            "  87 букв: 1 слов\n",
            "  90 букв: 1 слов\n",
            "  104 букв: 1 слов\n",
            "  105 букв: 2 слов\n",
            "  112 букв: 1 слов\n",
            "  114 букв: 1 слов\n"
          ]
        }
      ],
      "source": [
        "with open('convo_corpus.txt', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "# Статистика по очищенным данным\n",
        "total_words = len(all_cleaned_words)\n",
        "total_chars = 0\n",
        "word_lengths = []\n",
        "\n",
        "# Ваш код здесь: создайте список длин слов word_lengths\n",
        "#                и посчитайте общее количество символов total_chars\n",
        "\n",
        "for word in all_cleaned_words:\n",
        "    word_len = len(word)\n",
        "    word_lengths.append(word_len)\n",
        "    total_chars += word_len\n",
        "\n",
        "# Анализ длин слов: допишите код для подсчета количества слов разной длины\n",
        "word_length_count = {}\n",
        "# Ваш код здесь: для каждого значения длины в списке word_lengths\n",
        "for length in word_lengths:\n",
        "    # если длина уже зафиксирована в word_length_count, то выполняем:\n",
        "    if length in word_length_count:\n",
        "        word_length_count[length] += 1\n",
        "    # иначе: выполняем:\n",
        "    else:\n",
        "        word_length_count[length] = 1\n",
        "\n",
        "# Ожидаемый результат:\n",
        "print(f\"Слов после очистки: {total_words}\")\n",
        "print(f\"Символов после очистки: {total_chars}\")\n",
        "print(\"Распределение длин слов:\")\n",
        "for length in sorted(word_length_count.keys()):\n",
        "    print(f\"  {length} букв: {word_length_count[length]} слов\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQkDyl0-l2fw",
        "outputId": "226220b8-4e24-419f-dfaf-2610b93b1e86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слов после очистки: 3524835\n",
            "Символов после очистки: 14643162\n",
            "Распределение длин слов:\n",
            "  2 букв: 666389 слов\n",
            "  3 букв: 880968 слов\n",
            "  4 букв: 880766 слов\n",
            "  5 букв: 425302 слов\n",
            "  6 букв: 255069 слов\n",
            "  7 букв: 175610 слов\n",
            "  8 букв: 102856 слов\n",
            "  9 букв: 60865 слов\n",
            "  10 букв: 34706 слов\n",
            "  11 букв: 16675 слов\n",
            "  12 букв: 10611 слов\n",
            "  13 букв: 5627 слов\n",
            "  14 букв: 3330 слов\n",
            "  15 букв: 1970 слов\n",
            "  16 букв: 1292 слов\n",
            "  17 букв: 668 слов\n",
            "  18 букв: 558 слов\n",
            "  19 букв: 331 слов\n",
            "  20 букв: 262 слов\n",
            "  21 букв: 173 слов\n",
            "  22 букв: 162 слов\n",
            "  23 букв: 94 слов\n",
            "  24 букв: 98 слов\n",
            "  25 букв: 62 слов\n",
            "  26 букв: 45 слов\n",
            "  27 букв: 56 слов\n",
            "  28 букв: 32 слов\n",
            "  29 букв: 28 слов\n",
            "  30 букв: 31 слов\n",
            "  31 букв: 12 слов\n",
            "  32 букв: 34 слов\n",
            "  33 букв: 16 слов\n",
            "  34 букв: 14 слов\n",
            "  35 букв: 18 слов\n",
            "  36 букв: 17 слов\n",
            "  37 букв: 2 слов\n",
            "  38 букв: 3 слов\n",
            "  39 букв: 18 слов\n",
            "  40 букв: 3 слов\n",
            "  41 букв: 2 слов\n",
            "  42 букв: 6 слов\n",
            "  43 букв: 2 слов\n",
            "  44 букв: 3 слов\n",
            "  45 букв: 7 слов\n",
            "  47 букв: 4 слов\n",
            "  48 букв: 4 слов\n",
            "  49 букв: 1 слов\n",
            "  51 букв: 2 слов\n",
            "  53 букв: 1 слов\n",
            "  54 букв: 1 слов\n",
            "  56 букв: 2 слов\n",
            "  57 букв: 1 слов\n",
            "  58 букв: 1 слов\n",
            "  59 букв: 5 слов\n",
            "  60 букв: 7 слов\n",
            "  63 букв: 1 слов\n",
            "  65 букв: 4 слов\n",
            "  66 букв: 1 слов\n",
            "  87 букв: 1 слов\n",
            "  90 букв: 1 слов\n",
            "  104 букв: 1 слов\n",
            "  105 букв: 2 слов\n",
            "  112 букв: 1 слов\n",
            "  114 букв: 1 слов\n"
          ]
        }
      ],
      "source": [
        "with open('movie_corpus.txt', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "# Статистика по очищенным данным\n",
        "total_words = len(all_cleaned_words)\n",
        "total_chars = 0\n",
        "word_lengths = []\n",
        "\n",
        "# Ваш код здесь: создайте список длин слов word_lengths\n",
        "#                и посчитайте общее количество символов total_chars\n",
        "\n",
        "for word in all_cleaned_words:\n",
        "    word_len = len(word)\n",
        "    word_lengths.append(word_len)\n",
        "    total_chars += word_len\n",
        "\n",
        "# Анализ длин слов: допишите код для подсчета количества слов разной длины\n",
        "word_length_count = {}\n",
        "# Ваш код здесь: для каждого значения длины в списке word_lengths\n",
        "for length in word_lengths:\n",
        "    # если длина уже зафиксирована в word_length_count, то выполняем:\n",
        "    if length in word_length_count:\n",
        "        word_length_count[length] += 1\n",
        "    # иначе: выполняем:\n",
        "    else:\n",
        "        word_length_count[length] = 1\n",
        "\n",
        "# Ожидаемый результат:\n",
        "print(f\"Слов после очистки: {total_words}\")\n",
        "print(f\"Символов после очистки: {total_chars}\")\n",
        "print(\"Распределение длин слов:\")\n",
        "for length in sorted(word_length_count.keys()):\n",
        "    print(f\"  {length} букв: {word_length_count[length]} слов\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNdyoaFil619",
        "outputId": "88d8dabc-065d-4998-a27c-f3dfde3245d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слов после очистки: 3524835\n",
            "Символов после очистки: 14643162\n",
            "Распределение длин слов:\n",
            "  2 букв: 666389 слов\n",
            "  3 букв: 880968 слов\n",
            "  4 букв: 880766 слов\n",
            "  5 букв: 425302 слов\n",
            "  6 букв: 255069 слов\n",
            "  7 букв: 175610 слов\n",
            "  8 букв: 102856 слов\n",
            "  9 букв: 60865 слов\n",
            "  10 букв: 34706 слов\n",
            "  11 букв: 16675 слов\n",
            "  12 букв: 10611 слов\n",
            "  13 букв: 5627 слов\n",
            "  14 букв: 3330 слов\n",
            "  15 букв: 1970 слов\n",
            "  16 букв: 1292 слов\n",
            "  17 букв: 668 слов\n",
            "  18 букв: 558 слов\n",
            "  19 букв: 331 слов\n",
            "  20 букв: 262 слов\n",
            "  21 букв: 173 слов\n",
            "  22 букв: 162 слов\n",
            "  23 букв: 94 слов\n",
            "  24 букв: 98 слов\n",
            "  25 букв: 62 слов\n",
            "  26 букв: 45 слов\n",
            "  27 букв: 56 слов\n",
            "  28 букв: 32 слов\n",
            "  29 букв: 28 слов\n",
            "  30 букв: 31 слов\n",
            "  31 букв: 12 слов\n",
            "  32 букв: 34 слов\n",
            "  33 букв: 16 слов\n",
            "  34 букв: 14 слов\n",
            "  35 букв: 18 слов\n",
            "  36 букв: 17 слов\n",
            "  37 букв: 2 слов\n",
            "  38 букв: 3 слов\n",
            "  39 букв: 18 слов\n",
            "  40 букв: 3 слов\n",
            "  41 букв: 2 слов\n",
            "  42 букв: 6 слов\n",
            "  43 букв: 2 слов\n",
            "  44 букв: 3 слов\n",
            "  45 букв: 7 слов\n",
            "  47 букв: 4 слов\n",
            "  48 букв: 4 слов\n",
            "  49 букв: 1 слов\n",
            "  51 букв: 2 слов\n",
            "  53 букв: 1 слов\n",
            "  54 букв: 1 слов\n",
            "  56 букв: 2 слов\n",
            "  57 букв: 1 слов\n",
            "  58 букв: 1 слов\n",
            "  59 букв: 5 слов\n",
            "  60 букв: 7 слов\n",
            "  63 букв: 1 слов\n",
            "  65 букв: 4 слов\n",
            "  66 букв: 1 слов\n",
            "  87 букв: 1 слов\n",
            "  90 букв: 1 слов\n",
            "  104 букв: 1 слов\n",
            "  105 букв: 2 слов\n",
            "  112 букв: 1 слов\n",
            "  114 букв: 1 слов\n"
          ]
        }
      ],
      "source": [
        "with open('splited_corpus.txt', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "# Статистика по очищенным данным\n",
        "total_words = len(all_cleaned_words)\n",
        "total_chars = 0\n",
        "word_lengths = []\n",
        "\n",
        "# Ваш код здесь: создайте список длин слов word_lengths\n",
        "#                и посчитайте общее количество символов total_chars\n",
        "\n",
        "for word in all_cleaned_words:\n",
        "    word_len = len(word)\n",
        "    word_lengths.append(word_len)\n",
        "    total_chars += word_len\n",
        "\n",
        "# Анализ длин слов: допишите код для подсчета количества слов разной длины\n",
        "word_length_count = {}\n",
        "# Ваш код здесь: для каждого значения длины в списке word_lengths\n",
        "for length in word_lengths:\n",
        "    # если длина уже зафиксирована в word_length_count, то выполняем:\n",
        "    if length in word_length_count:\n",
        "        word_length_count[length] += 1\n",
        "    # иначе: выполняем:\n",
        "    else:\n",
        "        word_length_count[length] = 1\n",
        "\n",
        "# Ожидаемый результат:\n",
        "print(f\"Слов после очистки: {total_words}\")\n",
        "print(f\"Символов после очистки: {total_chars}\")\n",
        "print(\"Распределение длин слов:\")\n",
        "for length in sorted(word_length_count.keys()):\n",
        "    print(f\"  {length} букв: {word_length_count[length]} слов\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyupFb4Vl98X",
        "outputId": "d63b6ee0-9cfe-4f49-c866-685e186e5b22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Слов после очистки: 3524835\n",
            "Символов после очистки: 14643162\n",
            "Распределение длин слов:\n",
            "  2 букв: 666389 слов\n",
            "  3 букв: 880968 слов\n",
            "  4 букв: 880766 слов\n",
            "  5 букв: 425302 слов\n",
            "  6 букв: 255069 слов\n",
            "  7 букв: 175610 слов\n",
            "  8 букв: 102856 слов\n",
            "  9 букв: 60865 слов\n",
            "  10 букв: 34706 слов\n",
            "  11 букв: 16675 слов\n",
            "  12 букв: 10611 слов\n",
            "  13 букв: 5627 слов\n",
            "  14 букв: 3330 слов\n",
            "  15 букв: 1970 слов\n",
            "  16 букв: 1292 слов\n",
            "  17 букв: 668 слов\n",
            "  18 букв: 558 слов\n",
            "  19 букв: 331 слов\n",
            "  20 букв: 262 слов\n",
            "  21 букв: 173 слов\n",
            "  22 букв: 162 слов\n",
            "  23 букв: 94 слов\n",
            "  24 букв: 98 слов\n",
            "  25 букв: 62 слов\n",
            "  26 букв: 45 слов\n",
            "  27 букв: 56 слов\n",
            "  28 букв: 32 слов\n",
            "  29 букв: 28 слов\n",
            "  30 букв: 31 слов\n",
            "  31 букв: 12 слов\n",
            "  32 букв: 34 слов\n",
            "  33 букв: 16 слов\n",
            "  34 букв: 14 слов\n",
            "  35 букв: 18 слов\n",
            "  36 букв: 17 слов\n",
            "  37 букв: 2 слов\n",
            "  38 букв: 3 слов\n",
            "  39 букв: 18 слов\n",
            "  40 букв: 3 слов\n",
            "  41 букв: 2 слов\n",
            "  42 букв: 6 слов\n",
            "  43 букв: 2 слов\n",
            "  44 букв: 3 слов\n",
            "  45 букв: 7 слов\n",
            "  47 букв: 4 слов\n",
            "  48 букв: 4 слов\n",
            "  49 букв: 1 слов\n",
            "  51 букв: 2 слов\n",
            "  53 букв: 1 слов\n",
            "  54 букв: 1 слов\n",
            "  56 букв: 2 слов\n",
            "  57 букв: 1 слов\n",
            "  58 букв: 1 слов\n",
            "  59 букв: 5 слов\n",
            "  60 букв: 7 слов\n",
            "  63 букв: 1 слов\n",
            "  65 букв: 4 слов\n",
            "  66 букв: 1 слов\n",
            "  87 букв: 1 слов\n",
            "  90 букв: 1 слов\n",
            "  104 букв: 1 слов\n",
            "  105 букв: 2 слов\n",
            "  112 букв: 1 слов\n",
            "  114 букв: 1 слов\n"
          ]
        }
      ],
      "source": [
        "with open('bnc_corpus.txt', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "# Статистика по очищенным данным\n",
        "total_words = len(all_cleaned_words)\n",
        "total_chars = 0\n",
        "word_lengths = []\n",
        "\n",
        "# Ваш код здесь: создайте список длин слов word_lengths\n",
        "#                и посчитайте общее количество символов total_chars\n",
        "\n",
        "for word in all_cleaned_words:\n",
        "    word_len = len(word)\n",
        "    word_lengths.append(word_len)\n",
        "    total_chars += word_len\n",
        "\n",
        "# Анализ длин слов: допишите код для подсчета количества слов разной длины\n",
        "word_length_count = {}\n",
        "# Ваш код здесь: для каждого значения длины в списке word_lengths\n",
        "for length in word_lengths:\n",
        "    # если длина уже зафиксирована в word_length_count, то выполняем:\n",
        "    if length in word_length_count:\n",
        "        word_length_count[length] += 1\n",
        "    # иначе: выполняем:\n",
        "    else:\n",
        "        word_length_count[length] = 1\n",
        "\n",
        "# Ожидаемый результат:\n",
        "print(f\"Слов после очистки: {total_words}\")\n",
        "print(f\"Символов после очистки: {total_chars}\")\n",
        "print(\"Распределение длин слов:\")\n",
        "for length in sorted(word_length_count.keys()):\n",
        "    print(f\"  {length} букв: {word_length_count[length]} слов\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFZj9nmSeSGo"
      },
      "source": [
        "Часть 2: частотность слов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12uZ3UlLDSJv"
      },
      "outputs": [],
      "source": [
        "with open('lower_corpus.txt', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "# Считаем частотность слов (по аналогии с подсчетом word_length_count)\n",
        "word_frequency = {}\n",
        "# Ваш код здесь:\n",
        "for word in all_cleaned_words:\n",
        "    if word in word_frequency:\n",
        "        word_frequency[word] += 1\n",
        "    else:\n",
        "        word_frequency[word] = 1\n",
        "\n",
        "# Находим топ-10 самых частых слов\n",
        "# Начинаем с формирования кортежей вида (частотность слова, лексема)\n",
        "word_count_pairs = []\n",
        "for word, count in word_frequency.items():\n",
        "    word_count_pairs.append((count, word))\n",
        "\n",
        "# Сортируем вручную через вложенные циклы\n",
        "for i in range(len(word_count_pairs)):\n",
        "    for j in range(i + 1, len(word_count_pairs)):\n",
        "        if word_count_pairs[j][0] > word_count_pairs[i][0]:\n",
        "            # Меняем местами\n",
        "            temp = word_count_pairs[i]\n",
        "            word_count_pairs[i] = word_count_pairs[j]\n",
        "            word_count_pairs[j] = temp\n",
        "\n",
        "print(\"Топ-10 самых частых слов:\")\n",
        "for i in range(min(10, len(word_count_pairs))):\n",
        "    count, word = word_count_pairs[i]\n",
        "    print(f\"  {i+1}. '{word}': {count} раз\")\n",
        "\n",
        "# Анализ уникальных слов\n",
        "# Ваш код здесь: создайте множество unique_words\n",
        "unique_words = set(all_cleaned_words)\n",
        "\n",
        "print(f\"\\nВсего уникальных слов: {len(unique_words)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GjjejqWnetY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "b48913aa-2e4b-470f-9466-9978b1e89923"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1561531823.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_count_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_count_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mword_count_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mword_count_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0;31m# Меняем местами\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_count_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "with open('convo_corpus.txt', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "# Считаем частотность слов (по аналогии с подсчетом word_length_count)\n",
        "word_frequency = {}\n",
        "# Ваш код здесь:\n",
        "for word in all_cleaned_words:\n",
        "    if word in word_frequency:\n",
        "        word_frequency[word] += 1\n",
        "    else:\n",
        "        word_frequency[word] = 1\n",
        "\n",
        "# Находим топ-10 самых частых слов\n",
        "# Начинаем с формирования кортежей вида (частотность слова, лексема)\n",
        "word_count_pairs = []\n",
        "for word, count in word_frequency.items():\n",
        "    word_count_pairs.append((count, word))\n",
        "\n",
        "# Сортируем вручную через вложенные циклы\n",
        "for i in range(len(word_count_pairs)):\n",
        "    for j in range(i + 1, len(word_count_pairs)):\n",
        "        if word_count_pairs[j][0] > word_count_pairs[i][0]:\n",
        "            # Меняем местами\n",
        "            temp = word_count_pairs[i]\n",
        "            word_count_pairs[i] = word_count_pairs[j]\n",
        "            word_count_pairs[j] = temp\n",
        "\n",
        "print(\"Топ-10 самых частых слов:\")\n",
        "for i in range(min(10, len(word_count_pairs))):\n",
        "    count, word = word_count_pairs[i]\n",
        "    print(f\"  {i+1}. '{word}': {count} раз\")\n",
        "\n",
        "# Анализ уникальных слов\n",
        "# Ваш код здесь: создайте множество unique_words\n",
        "unique_words = set(all_cleaned_words)\n",
        "\n",
        "print(f\"\\nВсего уникальных слов: {len(unique_words)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUZFm-dfoLq_"
      },
      "outputs": [],
      "source": [
        "with open('movie_corpus.txt', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "# Считаем частотность слов (по аналогии с подсчетом word_length_count)\n",
        "word_frequency = {}\n",
        "# Ваш код здесь:\n",
        "for word in all_cleaned_words:\n",
        "    if word in word_frequency:\n",
        "        word_frequency[word] += 1\n",
        "    else:\n",
        "        word_frequency[word] = 1\n",
        "\n",
        "# Находим топ-10 самых частых слов\n",
        "# Начинаем с формирования кортежей вида (частотность слова, лексема)\n",
        "word_count_pairs = []\n",
        "for word, count in word_frequency.items():\n",
        "    word_count_pairs.append((count, word))\n",
        "\n",
        "# Сортируем вручную через вложенные циклы\n",
        "for i in range(len(word_count_pairs)):\n",
        "    for j in range(i + 1, len(word_count_pairs)):\n",
        "        if word_count_pairs[j][0] > word_count_pairs[i][0]:\n",
        "            # Меняем местами\n",
        "            temp = word_count_pairs[i]\n",
        "            word_count_pairs[i] = word_count_pairs[j]\n",
        "            word_count_pairs[j] = temp\n",
        "\n",
        "print(\"Топ-10 самых частых слов:\")\n",
        "for i in range(min(10, len(word_count_pairs))):\n",
        "    count, word = word_count_pairs[i]\n",
        "    print(f\"  {i+1}. '{word}': {count} раз\")\n",
        "\n",
        "# Анализ уникальных слов\n",
        "# Ваш код здесь: создайте множество unique_words\n",
        "unique_words = set(all_cleaned_words)\n",
        "\n",
        "print(f\"\\nВсего уникальных слов: {len(unique_words)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIUnvi_7oN1K"
      },
      "outputs": [],
      "source": [
        "with open('bnc_corpus.txt', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "# Считаем частотность слов (по аналогии с подсчетом word_length_count)\n",
        "word_frequency = {}\n",
        "# Ваш код здесь:\n",
        "for word in all_cleaned_words:\n",
        "    if word in word_frequency:\n",
        "        word_frequency[word] += 1\n",
        "    else:\n",
        "        word_frequency[word] = 1\n",
        "\n",
        "# Находим топ-10 самых частых слов\n",
        "# Начинаем с формирования кортежей вида (частотность слова, лексема)\n",
        "word_count_pairs = []\n",
        "for word, count in word_frequency.items():\n",
        "    word_count_pairs.append((count, word))\n",
        "\n",
        "# Сортируем вручную через вложенные циклы\n",
        "for i in range(len(word_count_pairs)):\n",
        "    for j in range(i + 1, len(word_count_pairs)):\n",
        "        if word_count_pairs[j][0] > word_count_pairs[i][0]:\n",
        "            # Меняем местами\n",
        "            temp = word_count_pairs[i]\n",
        "            word_count_pairs[i] = word_count_pairs[j]\n",
        "            word_count_pairs[j] = temp\n",
        "\n",
        "print(\"Топ-10 самых частых слов:\")\n",
        "for i in range(min(10, len(word_count_pairs))):\n",
        "    count, word = word_count_pairs[i]\n",
        "    print(f\"  {i+1}. '{word}': {count} раз\")\n",
        "\n",
        "# Анализ уникальных слов\n",
        "# Ваш код здесь: создайте множество unique_words\n",
        "unique_words = set(all_cleaned_words)\n",
        "\n",
        "print(f\"\\nВсего уникальных слов: {len(unique_words)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "vrtdr5UF_TyT",
        "JLaq0LFXBBI9",
        "vSc5RUhgBu_3",
        "aptZI3yhEOlW",
        "WvPQoLBzGvAS"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}